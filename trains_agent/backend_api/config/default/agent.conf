{
    # unique name of this worker, if None, created based on hostname:process_id
    # Override with os environment: TRAINS_WORKER_ID
    # worker_id: "trains-agent-machine1:gpu0"
    worker_id: ""

    # worker name, replaces the hostname when creating a unique name for this worker
    # Override with os environment: TRAINS_WORKER_NAME
    # worker_name: "trains-agent-machine1"
    worker_name: ""

    # Set GIT user/pass credentials for cloning code, leave blank for GIT SSH credentials.
    # git_user: ""
    # git_pass: ""

    # Set the python version to use when creating the virtual environment and launching the experiment
    # Example values: "/usr/bin/python3" or "/usr/local/bin/python3.6"
    # The default is the python executing the trains_agent
    python_binary: ""

    # select python package manager:
    # currently supported pip and conda
    # poetry is used if pip selected and repository contains poetry.lock file
    package_manager: {
        # supported options: pip, conda, poetry
        type: pip,

        # specify pip version to use (examples "<20", "==19.3.1", "", empty string will install the latest version)
        pip_version: "<20",

        # virtual environment inheres packages from system
        system_site_packages: false,

        # install with --upgrade
        force_upgrade: false,

        # additional artifact repositories to use when installing python packages
        # extra_index_url: ["https://allegroai.jfrog.io/trainsai/api/pypi/public/simple"]

        # additional conda channels to use when installing with conda package manager
        conda_channels: ["defaults", "conda-forge", "pytorch", ]
    },

    # target folder for virtual environments builds, created when executing experiment
    venvs_dir = ~/.trains/venvs-builds

    # cached git clone folder
    vcs_cache: {
        enabled: true,
        path: ~/.trains/vcs-cache
    },

    # use venv-update in order to accelerate python virtual environment building
    # Still in beta, turned off by default
    venv_update: {
        enabled: false,
    },

    # cached folder for specific python package download (used for pytorch package caching)
    pip_download_cache {
        enabled: true,
        path: ~/.trains/pip-download-cache
    },

    translate_ssh: true,
    # reload configuration file every daemon execution
    reload_config: false,

    # pip cache folder used mapped into docker, for python package caching
    docker_pip_cache = ~/.trains/pip-cache
    # apt cache folder used mapped into docker, for ubuntu package caching
    docker_apt_cache = ~/.trains/apt-cache

    # optional arguments to pass to docker image
    # these are local for this agent and will not be updated in the experiment's docker_cmd section
    # extra_docker_arguments: ["--ipc=host", ]

    # optional shell script to run in docker when started before the experiment is started
    # extra_docker_shell_script: ["apt-get install -y bindfs", ]

    # set to true in order to force "docker pull" before running an experiment using a docker image.
    # This makes sure the docker image is updated.
    docker_force_pull: false

    default_docker: {
        # default docker image to use when running in docker mode
        image: "nvidia/cuda"

        # optional arguments to pass to docker image
        # arguments: ["--ipc=host", ]
    }

    # cuda versions used for solving pytorch wheel packages
    # should be detected automatically. Override with os environment CUDA_VERSION / CUDNN_VERSION
    # cuda_version: 10.1
    # cudnn_version: 7.6
}
